# PDF Outline Extractor

## Challenge Overview
This solution addresses **Adobe's "Connecting the Dots" Challenge - Round 1A: Document Structure Extraction**

### Challenge Requirements
- Extract hierarchical document structure from PDF files
- Output JSON format with title and headings (H1, H2, H3, H4)
- Process PDFs up to 50 pages
- Performance constraint: â‰¤10 seconds per document
- CPU-only execution with â‰¤200MB model size
- Offline operation (no internet access)
- Multilingual support with bonus scoring

## Solution Architecture

### Core Components

#### 1. **Document Analysis Pipeline**
```bash
PDF Input â†’ Text Extraction â†’ Language Detection â†’ Document Classification â†’ Structure Analysis â†’ JSON Output
```

#### 2. **Multilingual Language Support**
- **English**: Pattern-based analysis with business/technical vocabulary
- **Japanese**: Hiragana/Katakana/Kanji script detection with honorifics
- **German**: Umlaut patterns, compound words, capitalization rules
- **Tamil**: Script-specific Unicode range analysis

#### 3. **Document Type Classification**
- **Form Documents**: Application forms, declarations
- **Technical Manuals**: Structured documentation with TOC
- **Business Documents**: RFPs, proposals, appendices
- **Program Documents**: Educational pathways, curricula
- **Invitation Documents**: Events, announcements

#### 4. **Hierarchical Structure Detection**
- **Font Analysis**: Size clustering, formatting detection
- **Spatial Analysis**: Layout patterns, positioning
- **Semantic Classification**: Content vs. structure differentiation
- **Pattern Matching**: Numbering schemes, formatting conventions

## Installation & Setup

### Prerequisites
```bash
Python 3.9+
Docker (for containerized execution)
```

### Dependencies
```bash
pip install -r requirements.txt
```


**Core Libraries:**
- `PyPDF2`: PDF parsing
- `pdfplumber`: Advanced text extraction
- `scikit-learn`: Font clustering analysis
- `numpy`: Numerical operations

### Directory Structure
```bash
PDF_OUTLINE_EXTRACTOR/
â”‚
â”œâ”€â”€ ğŸ“ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                          # Entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_classifier.py       # Document type classification
â”‚   â”‚   â”œâ”€â”€ title_extractor.py          # Smart title extraction
â”‚   â”‚   â”œâ”€â”€ outline_extractor.py        # Hierarchical outline extraction
â”‚   â”‚   â””â”€â”€ json_formatter.py           # Output formatting
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ analyzers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ font_analyzer.py            # Font clustering and analysis
â”‚   â”‚   â”œâ”€â”€ spatial_analyzer.py         # Layout and positioning analysis
â”‚   â”‚   â”œâ”€â”€ text_analyzer.py            # Text pattern recognition
â”‚   â”‚   â”œâ”€â”€ structure_analyzer.py       # Document structure detection
â”‚   â”‚   â””â”€â”€ language_analyzer.py        # Language detection and analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ classifiers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ content_filter.py           # Content vs structure filtering
â”‚   â”‚   â”œâ”€â”€ heading_detector.py         # Multi-level heading detection
â”‚   â”‚   â”œâ”€â”€ pattern_matcher.py          # Numbering and formatting patterns
â”‚   â”‚   â””â”€â”€ semantic_classifier.py      # Semantic content classification
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ processors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_processor.py           # Base processor class
â”‚   â”‚   â”œâ”€â”€ form_processor.py           # Form document processing
â”‚   â”‚   â”œâ”€â”€ manual_processor.py         # Technical manual processing
â”‚   â”‚   â”œâ”€â”€ business_processor.py       # Business document processing
â”‚   â”‚   â”œâ”€â”€ program_processor.py        # Program/curriculum processing
â”‚   â”‚   â””â”€â”€ invitation_processor.py     # Event/invitation processing
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ pdf_utils.py               # PDF parsing utilities
â”‚       â”œâ”€â”€ text_utils.py              # Text processing utilities
â”‚       â””â”€â”€ validation_utils.py        # Output validation
â”‚
â”œâ”€â”€ ğŸ“ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_types.py              # Document type definitions
â”‚   â”œâ”€â”€ heading_patterns.py            # Heading pattern definitions
â”‚   â””â”€â”€ extraction_rules.py            # Extraction rule engine 
â”‚
â”œâ”€â”€ ğŸ“ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py                    # Configuration settings
â”‚   â””â”€â”€ patterns.py                    # Pattern matching configurations
â”‚   â””â”€â”€ language_patterns.py
â”‚
â”œâ”€â”€ ğŸ“ input/                          # Input PDF files
â”‚
â”œâ”€â”€ ğŸ“ output/                         # Output JSON files
â”‚   â””â”€â”€ ğŸ“ Language Info/              # Language-specific outputs
â”‚
â”œâ”€â”€ ğŸ“ logs/                           # Logging directory
â”‚   â”œâ”€â”€ extraction.log                 # Extraction process logs
â”‚   â”œâ”€â”€ classification.log             # Document classification logs
â”‚   â””â”€â”€ errors.log                     # Error logs
â”‚
â”œâ”€â”€ ğŸ“ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_classifier.py            # Classification tests
â”‚   â”œâ”€â”€ test_extractors.py            # Extraction tests
â”‚   â””â”€â”€ test_processors.py            # Processor tests
â”‚
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ Dockerfile                         # Docker configuration
â””â”€â”€ README.md                          # Project documentationPDF_OUTLINE_EXTRACTOR/
```

### Build container
```bash
docker build --no-cache -t pdf_outline_extractor .
```

### Run with volume mounting
```bash
docker run --rm -v "${PWD}\input:/app/input" -v "${PWD}\output:/app/output" -v "${PWD}\logs:/app/logs" pdf_outline_extractor
```


### Performance Specifications

| Metric | Requirement | Our Solution |
|--------|-------------|--------------|
| **Processing Time** | â‰¤10 seconds | âœ… 3-8 seconds avg |
| **Hardcode** | Required | âœ… Zero-Hardcoding |
| **Page Limit** | 50 pages | âœ… Enforced |
| **CPU Only** | Required | âœ… No GPU dependencies |
| **Offline** | Required | âœ… No internet calls |
| **Multilingual Support** | Bonus | âœ… Implemented |

## Output Format

### Main Output (JSON)
```bash
{
"title": "Document Title Here",
"outline": [
{
  "level": "H1",
  "text": "Introduction",
  "page": 1
},
{
  "level": "H2",
  "text": "Background Information",
  "page": 2
}
  ]
    }
```

### Language Information (Separate File)

```bash
{
    "detected_language": "japanese",
    "confidence": 1.0,
    "display_name": "Japanese (æ—¥æœ¬èª)",
    "language_code": "ja",
    "confidence_level": "very_high",
    "language_processing_applied": true,
    "analysis_confidence_level": "very_high",
    "detection_scores": {
        "japanese": 1.0,
        "german": 0.2,
        "tamil": 0.0,
        "english": 0.2
    },
    "text_sample_length": 807,
    "threshold_applied": 0.4
}

```

## Algorithm Details

### 1. **Language Detection Pipeline**

def detect_language(text_blocks):
 - Script-based analysis for Japanese/Tamil
 - Pattern matching for German umlauts/compounds
 - Statistical analysis for English
 - Confidence scoring with thresholds


### 2. **Heading Detection Strategy**

def detect_headings(blocks, doc_type, font_analysis):
 - Multi-factor scoring:
 - Font size (25 points max)
 - Visual prominence (spatial analysis)
 - Pattern matching (numbering, formatting)
 - Semantic classification
 - Language-specific adjustments


### 3. **Title Extraction Logic**
- def extract_title(blocks, doc_type):
 - Document-type specific patterns
 - Font size hierarchy analysis
 - Position-based scoring
 - Language-aware processing


## Multilingual Capabilities

### Language-Specific Features

#### **Japanese Support**
- **Script Detection**: Hiragana (ã²ã‚‰ãŒãª), Katakana (ã‚«ã‚¿ã‚«ãƒŠ), Kanji (æ¼¢å­—)
- **Pattern Recognition**: Chapter markers (ç¬¬1ç« ), section numbering
- **Honorifics**: Recognition of ã•ã‚“, æ§˜, æ®¿ patterns
- **Business Terms**: æ ªå¼ä¼šç¤¾, æœ‰é™ä¼šç¤¾ identification

#### **German Support** 
- **Umlaut Processing**: Ã¤, Ã¶, Ã¼, ÃŸ character analysis
- **Compound Words**: Detection of long German compounds (12+ chars)
- **Capitalization**: German noun capitalization patterns
- **Grammar Patterns**: Articles (der, die, das), modal verbs

#### **Tamil Support**
- **Unicode Range**: Tamil script block (U+0B80-U+0BFF)
- **Numerals**: Tamil numeral recognition (à¯§à¯¨à¯©...)
- **Honorifics**: à®¤à®¿à®°à¯, à®¤à®¿à®°à¯à®®à®¤à®¿ identification
- **Question Words**: à®à®ªà¯à®ªà¯‹à®¤à¯, à®à®™à¯à®•à¯‡, à®à®ªà¯à®ªà®Ÿà®¿ patterns

## Performance Optimizations

### 1. **Font Clustering Algorithm**
 - K-means clustering for font hierarchy
 - Threshold-based size classification
 - Bold/italic formatting detection
 - Language-adjusted font weight scoring


### 2. **Memory Management**
- **Text Block Limiting**: Process max 10,000 blocks
- **Memory Cap**: 512MB maximum usage
- **Timeout Protection**: 30-second analysis limit
- **Resource Cleanup**: PDF handle management

### 3. **Processing Efficiency**
- **Early Termination**: Skip invalid/oversized PDFs
- **Lazy Loading**: On-demand component initialization
- **Pattern Compilation**: Regex pre-compilation
- **Caching**: Language detection result caching



## Scoring Alignment

### Adobe Challenge Scoring (45 points)

#### **Heading Detection Accuracy (25 points)**
-  **Pattern-based detection**: Numbering, formatting, positioning
-  **Multi-level hierarchy**: H1, H2, H3, H4 classification
-  **Document-type awareness**: Adaptive extraction rules
-  **Font analysis integration**: Size-based importance scoring

#### **Performance Compliance (10 points)**
-  **Processing speed**: 3-8 seconds average (â‰¤10 required)
-  **Memory efficiency**: ~45MB model size (â‰¤200MB limit)
-  **Page handling**: 50-page limit enforcement
-  **CPU-only execution**: No GPU dependencies

#### **Multilingual Handling Bonus (10 points)**
-  **4 Languages**: English, Japanese, German, Tamil
-  **Script detection**: Unicode range analysis
-  **Pattern adaptation**: Language-specific rules
-  **Confidence scoring**: Threshold-based validation

## Architecture Highlights

### **Modular Design**
- **Processors**: Document-type specific handling
- **Analyzers**: Font, spatial, text, structure analysis
- **Classifiers**: Content filtering, semantic classification
- **Language Support**: Pluggable language detection

### **Error Handling**
- **Graceful Degradation**: Fallback to English processing
- **Resource Protection**: Memory and timeout limits
- **Input Validation**: PDF format and size checking
- **Exception Logging**: Comprehensive error tracking

### **Extensibility**
- **New Languages**: Easy addition via pattern configuration
- **Document Types**: Pluggable processor architecture
- **Analysis Methods**: Modular analyzer components
- **Output Formats**: Configurable JSON formatting

## Contributors
- Harshita Ravindran Revathi
- Jayanth.C.R

**Note**: This solution prioritizes **accuracy**, **performance**, and **multilingual support** as per Adobe's Challenge requirements while maintaining clean, maintainable code architecture.



